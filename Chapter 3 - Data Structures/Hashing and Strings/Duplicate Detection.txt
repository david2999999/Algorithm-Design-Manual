Duplicate Detection Via Hashing
    - The key idea of hashing is to represent a large object using a single number
        - the goal is a representation of the large object by an entity that can be manipulated in constant time
        - It is relatively unlikely that two different large objects map to the same value

    - Consider the following problems with nice hashing solutions
        - Is a given document different from all the rest in a large corpus?
            - Explicitly comparing the new document D to all n documents is hopelessly inefficient for a large corpus
            - We can hash D to an integer and compare it to the hashcodes of the rest of the corpus
                - Since, we expect few spurious collisions, we can explicitly compare the few documents sharing the exact hash code
                  with little effort.